{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install azure-ai-textanalytics"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Requirement already satisfied: azure-ai-textanalytics in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (5.3.0)\nRequirement already satisfied: azure-core<2.0.0,>=1.24.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from azure-ai-textanalytics) (1.27.1)\nRequirement already satisfied: azure-common~=1.1 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from azure-ai-textanalytics) (1.1.28)\nRequirement already satisfied: isodate<1.0.0,>=0.6.1 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from azure-ai-textanalytics) (0.6.1)\nRequirement already satisfied: typing-extensions>=4.0.1 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from azure-ai-textanalytics) (4.6.3)\nRequirement already satisfied: requests>=2.18.4 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from azure-core<2.0.0,>=1.24.0->azure-ai-textanalytics) (2.31.0)\nRequirement already satisfied: six>=1.11.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from azure-core<2.0.0,>=1.24.0->azure-ai-textanalytics) (1.16.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from requests>=2.18.4->azure-core<2.0.0,>=1.24.0->azure-ai-textanalytics) (3.1.0)\nRequirement already satisfied: idna<4,>=2.5 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from requests>=2.18.4->azure-core<2.0.0,>=1.24.0->azure-ai-textanalytics) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from requests>=2.18.4->azure-core<2.0.0,>=1.24.0->azure-ai-textanalytics) (1.26.16)\nRequirement already satisfied: certifi>=2017.4.17 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from requests>=2.18.4->azure-core<2.0.0,>=1.24.0->azure-ai-textanalytics) (2023.5.7)\nNote: you may need to restart the kernel to use updated packages.\n"
        }
      ],
      "execution_count": 52,
      "metadata": {
        "gather": {
          "logged": 1714937769746
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cognitive_key ='9c0782e45754480c9a91da664488f94f'\n",
        "cognitive_endpoint='https://jmp-language.cognitiveservices.azure.com/'\n",
        "\n",
        "from azure.core.credentials import AzureKeyCredential\n",
        "from azure.ai.textanalytics import TextAnalyticsClient, TextDocumentInput\n",
        "\n",
        "credential=AzureKeyCredential(cognitive_key)\n",
        "text_analytics_client=TextAnalyticsClient(endpoint=cognitive_endpoint, credential=credential)"
      ],
      "outputs": [],
      "execution_count": 25,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1714930264859
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "documents=[\n",
        "\n",
        "    \"A little progress each day adds up to big results.\",\n",
        "    \"સાવ બેઠો છું કોઈ કામ નથી,આવ,ગૂંચવાયેલી લટને સૂલઝાવું,લાવ.\",\n",
        "    \"ترحيب حار في بلدي ابن عم\",\n",
        "    \" वक्ता अपने हृदयस्थ भावों को कम-से-कम शब्दों में प्रभावपूर्ण ढंग से सफलतापूर्वक अभिव्यक्त कर देता है।\",\n",
        "    \"La façon de commencer est d’arrêter de parler et de commencer à faire.\",\n",
        "    \"İş, sınavlar, ev ödevleri, derse zamanında yetişme ve sosyal bir hayata sahip olma arasında hokkabazlık yapmaya çalışıyorsunuz.\"\n",
        "\n",
        "    ]\n",
        "\n",
        "language_analysis = text_analytics_client.detect_language(documents)\n",
        "\n",
        "result=[ doc for doc in language_analysis if not doc.is_error]\n",
        "\n",
        "for doc in result:\n",
        "    print(\"Language Detected:{}\".format(doc.primary_language.name))\n",
        "    print(\"ISO6391 name:{}\".format(doc.primary_language.iso6391_name))\n",
        "    print(\"Confidence score:{}\\n\".format(doc.primary_language.confidence_score))\n",
        "\n",
        "response = text_analytics_client.analyze_sentiment(documents)\n",
        "\n",
        "for doc in response:\n",
        "    print(\"Overall sentiment: {}\".format(doc.sentiment))\n",
        "    print(\"Scores: positive={}, neutral={}, negative={}\\n\".format(\n",
        "        doc.confidence_scores.positive,\n",
        "        doc.confidence_scores.neutral,\n",
        "        doc.confidence_scores.negative,\n",
        "    ))\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, jaccard_score, f1_score,log_loss, mean_absolute_error, mean_squared_error, r2_score\n",
        "\n",
        "# Example ground truth and predicted language labels (replace with your actual data)\n",
        "actual_labels = [\"English\", \"Gujarati\", \"Arabic\", \"Hindi\", \"French\", \"Turkish\"]\n",
        "predicted_labels = [\"English\", \"Gujarati\", \"Arabic\", \"German\", \"French\", \"Turkish\"]\n",
        "\n",
        "# Calculate accuracy score\n",
        "accuracy = accuracy_score(actual_labels, predicted_labels)\n",
        "print(f\"Accuracy Score: {accuracy:.4f}\")\n",
        "\n",
        "# Calculate Jaccard index\n",
        "jaccard = jaccard_score(actual_labels, predicted_labels, average=\"weighted\")\n",
        "print(f\"Jaccard Index: {jaccard:.4f}\")\n",
        "\n",
        "# Calculate F1-score\n",
        "f1 = f1_score(actual_labels, predicted_labels, average=\"weighted\")\n",
        "print(f\"F1-Score: {f1:.4f}\")\n",
        "\n",
        "y_true = np.array([1, 0, 1, 0, 1])\n",
        "y_pred_probs = np.array([0.9, 0.2, 0.8, 0.1, 0.95])\n",
        "\n",
        "# Calculate log loss\n",
        "logloss = log_loss(y_true, y_pred_probs)\n",
        "print(f\"Log Loss: {logloss:.4f}\")\n",
        "\n",
        "# Example ground truth and predicted values (replace with your actual data)\n",
        "y_true_regression = np.array([3, -0.5, 2, 7])\n",
        "y_pred_regression = np.array([2.5, 0.0, 2, 8])\n",
        "\n",
        "# Calculate MAE\n",
        "mae = mean_absolute_error(y_true_regression, y_pred_regression)\n",
        "print(f\"Mean Absolute Error: {mae:.4f}\")\n",
        "\n",
        "# Calculate MSE\n",
        "mse = mean_squared_error(y_true_regression, y_pred_regression)\n",
        "print(f\"Mean Squared Error: {mse:.4f}\")\n",
        "\n",
        "# Calculate R2-score\n",
        "r2 = r2_score(y_true_regression, y_pred_regression)\n",
        "print(f\"R2-Score: {r2:.4f}\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Language Detected:English\nISO6391 name:en\nConfidence score:1.0\n\nLanguage Detected:Gujarati\nISO6391 name:gu\nConfidence score:1.0\n\nLanguage Detected:Arabic\nISO6391 name:ar\nConfidence score:1.0\n\nLanguage Detected:Hindi\nISO6391 name:hi\nConfidence score:1.0\n\nLanguage Detected:French\nISO6391 name:fr\nConfidence score:1.0\n\nLanguage Detected:Turkish\nISO6391 name:tr\nConfidence score:1.0\n\nOverall sentiment: neutral\nScores: positive=0.44, neutral=0.54, negative=0.02\n\nOverall sentiment: neutral\nScores: positive=0.13, neutral=0.58, negative=0.29\n\nOverall sentiment: positive\nScores: positive=0.57, neutral=0.41, negative=0.02\n\nOverall sentiment: neutral\nScores: positive=0.45, neutral=0.53, negative=0.01\n\nOverall sentiment: neutral\nScores: positive=0.05, neutral=0.87, negative=0.08\n\nOverall sentiment: neutral\nScores: positive=0.12, neutral=0.86, negative=0.02\n\nAccuracy Score: 0.8333\nJaccard Index: 0.8333\nF1-Score: 0.8333\nLog Loss: 0.1417\nMean Absolute Error: 0.5000\nMean Squared Error: 0.3750\nR2-Score: 0.9486\n"
        }
      ],
      "execution_count": 51,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1714937677565
        },
        "collapsed": true
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python310-sdkv2",
      "language": "python",
      "display_name": "Python 3.10 - SDK v2"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.11",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}